{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUWQJdVnWbo++9/Lq2wFkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monkrus/sagemaker_hugginface/blob/main/sagemaker_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjZo6TfAxDwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note Amazon SageMaker is a **paid service**.This code implies creating  single user SageMaker domain on AWS Sagemaker.We create a Jupyter lab space on SageMaker studio, using *ml.m5.2xlarge* as an instance.Storage is set to 10 GB."
      ],
      "metadata": {
        "id": "FH25NJgKxXHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sagemaker"
      ],
      "metadata": {
        "id": "Wd_DtdlYxk39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "\n",
        "sess = sagemaker.Session()\n",
        "#SM bucket is used for uploading dat, models and logs\n",
        "sagemaker_session_bucket=None\n",
        "if sagemaker_session_bucket is None and sess is not None:\n",
        "    sagemaker_session_bucket=sess.default_bucket()\n",
        "try:\n",
        " # or use `pass` as a placeholder for the role\n",
        "    role = sagemaker.get_execution_role()\n",
        "except ValueError:\n",
        "    iam = boto3.client('iam')\n",
        "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
        "\n",
        "session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
        "\n",
        "print(f\"sagemaker role arn: {role}\")\n",
        "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
        "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
      ],
      "metadata": {
        "id": "IaUU535YzuL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.huggingface.model import HuggingFaceModel\n",
        "\n",
        "# Hub model configuration <https://huggingface.co/models>\n",
        "hub = {\n",
        "  'HF_MODEL_ID':'distilbert-base-uncased-distilled-squad', # model_id from hf.co/models\n",
        "  'HF_TASK':'question-answering'                           # NLP task you want to use for predictions\n",
        "}\n",
        "\n",
        "# create Hugging Face Model Class\n",
        "huggingface_model = HuggingFaceModel(\n",
        "   env=hub,                                                # configuration for loading model from Hub\n",
        "   role=role,                                              # IAM role with permissions to create an endpoint\n",
        "   transformers_version=\"4.26\",                             # Transformers version used\n",
        "   pytorch_version=\"1.13\",                                  # PyTorch version used\n",
        "   py_version='py39',                                      # Python version used\n",
        ")\n",
        "\n",
        "# deploy model to SageMaker Inference\n",
        "predictor = huggingface_model.deploy(\n",
        "   initial_instance_count=1,\n",
        "   instance_type=\"ml.m5.xlarge\"\n",
        ")\n",
        "\n",
        "# example request: you always need to define \"inputs\"\n",
        "data = {\n",
        "\"inputs\": {\n",
        "\t\"question\": \"What is used for inference?\",\n",
        "\t\"context\": \"My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.\"\n",
        "\t}\n",
        "}\n",
        "\n",
        "# request\n",
        "predictor.predict(data)"
      ],
      "metadata": {
        "id": "1Zf9bdwqfBOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}